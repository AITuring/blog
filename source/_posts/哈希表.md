---
title: Python算法4——哈希表
date: 2020-03-07 10:28:12
tags: [python,算法,哈希表]
categories: [《数据结构与算法Python语言描述》]
---

<img src="http://lishengyu.xyz/pubgm/IMG_5390.JPG" >


### 哈希函数

hash（散列、杂凑）函数，是将任意长度的数据映射到有限长度的域上。直观解释起来，就是对一串数据m进行杂糅，输出另一段固定长度的数据h，作为这段数据的特征（指纹）。也就是说，无论数据块m有多大，其输出值h为固定长度。到底是什么原理？将m分成固定长度（如128位），依次进行hash运算，然后用不同的方法迭代即可（如前一块的hash值与后一块的hash值进行异或）。如果不够128位怎么办？用0补全或者用1补全随意，算法中约定好就可以了。

所有的哈希函数都具有如下一个基本特性：如果两个散列值是不相同的（根据同一函数），那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有确定性的结果，具有这种性质的散列函数称为单向散列函数。

### 哈希表

哈希表属于一种物理存储结构，它应用了哈希算法因此称之为哈希表。物理存储结构共4种：顺序、链式、索引、散列，其中顺序和链式最常见，这两种存储结构的共同特征是元素之间有着映射关系，而哈希表（散列存储结构）的元素之间相互独立。索引存储结构类似现实世界中的字典目录。

哈希表的实现方式：给定一个任意类型的数据，称为键，使用哈希算法加工该数据，把生成的结果作为键的存储地址。例如给定一个字符串参数 "str"，该键对应的元素是"jack"，那么"jack"的存储地址就是通过哈希算法对"str"进行加工生成的。这么一来，每当存取元素时不会像传统的数据结构逐个遍历、一一对比，而是通过哈希算法直接获取元素的存储地址，因此哈希表会比传统的数据结构更为高效，这也是使用哈希表的原因。

#### 实现哈希表的要点

- 若关键字为k，则其值存放在f(k)的存储位置上。由此，不需比较便可直接取得所查记录。称这个对应关系f为散列函数，按这个思想建立的表为散列表。

- 对不同的关键字可能得到同一散列地址，即k1≠k2，而f(k1)=f(k2)，这种现象称为冲突。具有相同函数值的关键字对该散列函数来说称做同义词。综上所述，根据散列函数f(k)和处理冲突的方法将一组关键字映射到一个有限的连续的地址集（区间）上，并以关键字在地址集中的“像”作为记录在表中的存储位置，这种表便称为散列表，这一映射过程称为散列造表或散列，所得的存储位置称散列地址。

- 若对于关键字集合中的任一个关键字，经散列函数映象到地址集合中任何一个地址的概率是相等的，则称此类散列函数为均匀散列函数（Uniform Hash function），这就是使关键字经过散列函数得到一个“随机的地址”，从而减少冲突。

#### 建立哈希表

其实，哈希表就是一个具备映射关系的表，我们可以通过映射关系由键找到值。下面是一个简单的哈希表：

```python
class Map:
    def __init__(self):
        self.items =[None]*100
    def hash(self,a):
        return a*1+0
    def put(self,k,v):
        self.items[hash(k)] = v
    def get(self,k):
        hashcode=hash(k)
        return self.items[hashcode]
```

这个哈希函数十分简单，但简单不妨碍它成为一个哈希函数，事实上，它叫直接定址法，是一个线性函数： $hash(k)= a*k+b$

直接定址法的优点很明显，就是它不会产生重复的hash值。但由于它与键值本身有关系，所以当键值分布很散的时候，会浪费大量的存储空间。所以一般是不会用到直接定址法的。


#### 处理冲突

假如某个hash函数产生了一堆哈希值，而这些哈希值产生了冲突怎么办（实际生产环境中经常发生）？在各种哈希表的实现里，处理冲突是必需的一步。
比如你定义了一个hash函数：
$$hash(k)=k mod 10$$
假设key序列为：[15,1,24,32,55,64,42,93,82,76]

| 0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|  ----  | ----  |----  |----  |----  |----  |----  |----  |----  |----  |
|   | 1 | 32 |93 |24 | 15 |76| | | |
| | |42 |  |64 |55 || || |
|  |  | 82| | | | | | | |

一趟下来，冲突的元素有四个，下面有几个办法。

##### 开放定址法

开放定址法就是产生冲突之后去寻找下一个空闲的空间。函数定义为：

$$hash_i=(hash(key)+d_i) \ mod \ m,i=1,2,...,k(k<=m-1>)$$

其中，hash(key)是哈希函数，$d_i$是增量序列，i为已冲突的次数。

##### 线性探测法
逐个探测存放地址的表，直到查找到一个空单元，然后放置在该单元。

例如：[15,1,24,32,55,64,42,93,82,76]

可以看到，在55之前都还没冲突：
| 0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|  ----  | ----  |----  |----  |----  |----  |----  |----  |----  |----  |
|   | 1 | 32 | |24 | 15 || | | |

此时插入55，与15冲突，用线性探测，此时i=1，可以在6处插入：
| 0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|  ----  | ----  |----  |----  |----  |----  |----  |----  |----  |----  |
|   | 1 | 32 | |24 | 15 |55| | | |

再插入64,冲突不少，要取到i=3：

| 0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|  ----  | ----  |----  |----  |----  |----  |----  |----  |----  |----  |
|   | 1 | 32 | |24 | 15 |55|64 | | |

插入42，i=1：
| 0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|  ----  | ----  |----  |----  |----  |----  |----  |----  |----  |----  |
|   | 1 | 32 |42 |24 | 15 |55|64 | | |

插入93，i=5：
| 0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|  ----  | ----  |----  |----  |----  |----  |----  |----  |----  |----  |
|   | 1 | 32 |42 |24 | 15 |55|64 |93 | |

插入82，i=7：
| 0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|  ----  | ----  |----  |----  |----  |----  |----  |----  |----  |----  |
|   | 1 | 32 |42 |24 | 15 |55|64 |93 | 82|

插入76，i=4：
| 0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|  ----  | ----  |----  |----  |----  |----  |----  |----  |----  |----  |
| 76  | 1 | 32 |42 |24 | 15 |55|64 |93 | 82|

发现越到后面，冲突的越来越离谱。所以，表的大小选择也很重要，此例中选择了10作为表的大小，所以容易产生冲突。**一般来讲，越是质数，mod取余就越可能分布的均匀**。

##### 平方探测 
di是$1^2$,$2^2$,...,$k^2$$(k<=m/2)$
##### 伪随机探测 
di是一个随机数序列
##### 链表法
这是另外一种类型解决冲突的办法，散列到同一位置的元素，不是继续往下探测，而是在这个位置是一个链表，这些元素则都放到这一个链表上。java的HashMap就采用的是这个。
##### 再散列
如果一次不够，就再来一次，直到冲突不再发生。
##### 建立公共溢出区
将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表(注意：在这个方法里面是把元素分开两个表来存储)。

下面是一个开放地址法的例子：

```python
class Map:
    def __init__(self):
        self.hash_table=[[None,None]for i in range(11)]
    
    def hash(self,k,i):
        h_value=(k+i)%11
        if self.hash_table[h_value][0]==k:
            return h_value
        if self.hash_table[h_value][0]!=None:
            i+=1
            h_value=self.hash(k,i)
        return h_value
 
    def put(self,k,v):
        hash_v=self.hash(k,0)
        self.hash_table[hash_v][0]=k
        self.hash_table[hash_v][1]=v

    def get(self,k):
        hash_v=self.hash(k,0)
        return self.hash_table[hash_v][1]
```

这里有一个概念，叫做载荷因子（load factor）。载荷因子的定义为：
$$α= \frac{已有的元素个数}{表的长度}$$
由于表长是定值， α与“填入表中的元素个数”成正比，所以， α越大，表明填入表中的元素越多，产生冲突的可能性就越大；反之，α越小，表明填入表中的元素越少，产生冲突的可能性就越小。实际上，散列表的平均查找长度是载荷因子 α的函数，只是不同处理冲突的方法有不同的函数。

所以当到达一定程度，表的长度是要变的，像java的HashMap，载荷因子被设计为0.75；超过0.8，cpu的cache missing会急剧上升。可以看下这篇讨论：

具体扩容多少，一般选择扩到已插入元素数量的两倍，java也是这么做的。
接着上面，再升级一下我们的map：

```python
class Map:
    def __init__(self):
        self.capacity=11
        self.hash_table=[[None,None]for i in range(self.capacity)]
        self.num=0
        self.load_factor=0.75
    
    def hash(self,k,i):
        h_value=(k+i)%self.capacity
        if self.hash_table[h_value][0]==k:
            return h_value
        if self.hash_table[h_value][0]!=None:
            i+=1
            h_value=self.hash(k,i)
        return h_value

    def resize(self):
        self.capacity=self.num*2 #扩容到原有元素数量的两倍
        temp=self.hash_table[:]
        self.hash_table=[[None,None]for i in range(self.capacity)] 
        for i in temp:
            if(i[0]!=None):  #把原来已有的元素存入
                hash_v=self.hash(i[0],0)
                self.hash_table[hash_v][0]=i[0]
                self.hash_table[hash_v][1]=i[1]
 
    def put(self,k,v):
        hash_v=self.hash(k,0)
        self.hash_table[hash_v][0]=k
        self.hash_table[hash_v][1]=v
        self.num+=1                 #暂不考虑key重复的情况，具体自己可以优化
        if(self.num/len(self.hash_table)>self.load_factor):# 如果比例大于载荷因子
            self.resize()

    def get(self,k):
        hash_v=self.hash(k,0)
        return self.hash_table[hash_v][1]
```

看上面的函数，可以看到resize是一个比较耗时的操作，因为只是原理教学，所以并没有什么奇淫技巧在里面。可以去看一下Java的HashMap的hash方法和resize方法，还有处理冲突时的设计（jdk8及之后的HashMap用到了红黑树），其中的思路要精妙的多。

关于哈希表，原理的东西都基本差不多了。可以看到，它本质要解决的是查找时间的问题。如果顺序查找的话，时间复杂度为O(n)；而哈希表，时间复杂度则为O(1)！直接甩了一个次元，这也就是为什么在大量数据存储查找的时候，哈希表得到大量应用的原因。







